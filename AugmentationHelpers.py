{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"script","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport matplotlib as mpl\nimport albumentations as A\nimport cv2\nimport tensorflow as tf\n\n\"\"\"\nAll the functions are built in such a way to be compatible with the tensorflow Dataset API.\nThis is the reason why all functions are annotated with @tf.py_function(...)\nTo make this integration process possible, some data conversion steps are required between tensors and\nnumpy arrays (in and out of the functions).\n\"\"\"\n\n\n@tf.py_function(Tout=[tf.uint8, tf.uint8])\ndef apply_geometric_transform(images, masks):\n    \"\"\"\n    Simple helper function that takes in an array of images and the corresponding masks\n    and applies a series of geometric transformations on both. It returns the two arrays of transformed\n    images and masks as nparrays.\n    \"\"\"\n\n    transformation = A.Compose(\n        [\n            A.Rotate(p=0.9),\n            A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, p=0.9),\n            A.HorizontalFlip(p=0.7),\n            A.VerticalFlip(p=0.7),\n            A.ElasticTransform(alpha=10, sigma=10, interpolation=cv2.INTER_NEAREST, p=0.6),   # alpha for distortion level, sigma for smoothness\n            A.Perspective(),\n            A.GridDistortion()\n        ]\n    )\n    \n    images=images.numpy()\n    masks = masks.numpy()\n    n_images = len(images)\n    result_images = []\n    result_masks = []\n    \n    for index in range(0, n_images):\n        # The application of the transformation returns a dictionary with two keys\n        # \"image\" : modified image\n        # \"mask\" : modified mask\n        result_dict = transformation(image=images[index], mask=masks[index])\n        result_images.append(result_dict[\"image\"])\n        result_masks.append(result_dict[\"mask\"])\n\n    return np.array(result_images), np.array(result_masks)\n        \n\n\n@tf.py_function(Tout=[tf.uint8, tf.uint8])\ndef apply_intensity_transform(images, masks):\n    \"\"\"\n    Simple helper function that takes in an array of images and the corresponding masks\n    and applies a series of \"intensity\" transformations, which modify pixel values to achieve\n    common \"colour distortions\". It returns the two arrays of transformed\n    images and masks as nparrays.\n\n    Notice: for these types of transformations, the library expects the input images in two possible formats:\n    - floating point values in the range [0.0, 1.0]\n    - integers in the range [0, 255]\n    It is therefore necessary to cast the images to hold integer pixel values before passing them in.\n    \"\"\"\n    transformation = A.Compose(\n        [\n            A.RandomBrightnessContrast(p=0.9),\n            A.CLAHE(p=0.7),\n            A.Sharpen(p=0.5),\n            A.MotionBlur(p=0.6),\n        ]\n    )\n\n    images=images.numpy()\n    masks = masks.numpy()\n    n_images = len(images)\n    result_images = []\n    result_masks = []\n    \n    for index in range(0, n_images):\n        # The application of the transformation returns a dictionary with two keys\n        # \"image\" : modified image\n        # \"mask\" : modified mask\n        result_dict = transformation(image=images[index], mask=masks[index])\n        result_images.append(result_dict[\"image\"])\n        result_masks.append(result_dict[\"mask\"])\n\n    return result_images, result_masks\n\n\n    \n\n@tf.py_function(Tout=[tf.uint8, tf.uint8])\ndef apply_total_transform(images, masks):\n    \"\"\"\n    Simple helper function that takes in an array of images and the corresponding masks\n    and applies a combination of geometric and pixel intensity transformations. \n    It returns the two arrays of transformed images and masks as nparrays.\n\n    Notice: since many different types of augmentation steps are listed, the parameters \n    are tuned to mitigate and control the effects of each component of the pipeline (eccessive \n    augmentation is not advisable).\n    \"\"\"\n    transformation = A.Compose(\n        [\n            A.SomeOf(\n                [\n                    A.RandomBrightnessContrast(p=0.5),\n                    A.CLAHE(p=0.5, clip_limit=1.1),\n                    A.Sharpen(p=0.3, alpha=(0.1,0.25), lightness=(0.9,1)),\n                    A.MotionBlur(p=0.4, blur_limit=5)\n                ],\n                n=2,\n                replace=False\n            ),\n            A.SomeOf(\n                [\n                    A.Rotate(p=1),\n                    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=1),\n                    A.HorizontalFlip(p=1),\n                    A.VerticalFlip(p=1),\n                    A.ElasticTransform(alpha=5, sigma=5, interpolation=cv2.INTER_NEAREST, p=0.3),   # alpha for distortion level, sigma for smoothness\n                    A.Perspective(p=0.3),\n                    A.GridDistortion(p=0.3)\n                ],\n                n=3,\n                replace=False \n            ), \n        ]\n    )\n\n    images=images.numpy()\n    masks = masks.numpy()\n    n_images = len(images)\n    result_images = []\n    result_masks = []\n    \n    for index in range(0, n_images):\n        # The application of the transformation returns a dictionary with two keys\n        # \"image\" : modified image\n        # \"mask\" : modified mask\n        result_dict = transformation(image=images[index], mask=masks[index])\n        result_images.append(result_dict[\"image\"])\n        result_masks.append(result_dict[\"mask\"])\n\n    return result_images, result_masks\n\n\n\n\n\n\ndef plot_images_and_masks(aug_imgs, aug_msks, original_imgs, original_msks, grid=(10, 4), figsize=(20, 30), cmap='gray'):\n\n    \"\"\"\n    Helper function to verify the correct functioning of augmentation or image transformations.\n    The aug_imgs and aug_msks parameters are the arrays of transformed images and masks, while original_imgs and original_msks\n    are the original images from the data set.\n    By default, the function works well with 10 images, but it is possible to change the parameters to adapt it to \n    a varying size of inputs.\n\n    Notice: when plotting grayscale or masks, it is necessary to specify vmin and vmax to the plotting function\n    so that no rescaling is performed on the input data by the library\n    \n    \"\"\"\n    \n    # Define a colormap to simplify the visualisation of the classes on the masks\n    # Background (0) -> black\n    # Soil (1) -> red\n    # Bedrock (2) -> blue\n    # Sand (3) -> green\n    # Big Rock (4) -> yellow\n    mask_colormap = mpl.colors.ListedColormap([\"black\", \"red\", \"blue\", \"green\", \"yellow\"])\n\n    image_count = len(original_imgs)\n    \n    figure = mpl.pyplot.figure(figsize=figsize)\n    axes_array = figure.subplots(grid[0], grid[1])\n    axes_array = axes_array.flatten()\n    \n\n    for img_index, ax_index  in zip(range(0, image_count), range(0, image_count * 4, 4)):\n        # Plot original image\n        axes_array[ax_index].imshow(original_imgs[img_index], cmap=cmap, vmin=0, vmax=255)\n        axes_array[ax_index].axis('off')\n        # Plot original mask\n        axes_array[ax_index + 1].imshow(original_msks[img_index], cmap=mask_colormap, vmin=0, vmax=4) \n        axes_array[ax_index + 1].axis('off')\n        # Plot augmented image\n        axes_array[ax_index + 2].imshow(aug_imgs[img_index], cmap=cmap, vmin=0, vmax=255)\n        axes_array[ax_index + 2].axis('off')\n        # Plot \"augmented\" mask\n        axes_array[ax_index + 3].imshow(aug_msks[img_index], cmap=mask_colormap, vmin=0, vmax=4) \n        axes_array[ax_index + 3].axis('off')\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-05T00:42:08.337984Z","iopub.execute_input":"2024-12-05T00:42:08.338360Z","iopub.status.idle":"2024-12-05T00:42:24.835154Z","shell.execute_reply.started":"2024-12-05T00:42:08.338322Z","shell.execute_reply":"2024-12-05T00:42:24.833952Z"}},"outputs":[],"execution_count":1}]}